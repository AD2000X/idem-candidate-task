{
  "language": "English",
  "dataset_info": {
    "total_sentences": 289781,
    "simple_vikidia_count": 17305,
    "complex_wikipedia_count": 272476
  },
  "anchor_selection": {
    "q1": 16.0,
    "q3": 29.0,
    "n_simple_anchors": 8773,
    "n_complex_anchors": 73032,
    "total_anchors": 81805
  },
  "anchor_quality": {
    "anchor_ratio": 0.28229939160952583,
    "n_total": 289781,
    "n_anchor": 81805,
    "lengthwords_global_mean": 23.751795321294356,
    "lengthwords_global_std": 13.026731924340385,
    "lengthwords_anchor_mean": 36.21982763889738,
    "lengthwords_anchor_std": 17.51150834583094,
    "anchor_source_breakdown": {
      "wiki": 73032,
      "viki": 8773
    },
    "anchor_label_breakdown": {
      "simple_0": 8773,
      "complex_1": 73032
    }
  },
  "anchor_shuffle_sanity_check": {
    "n_samples_used": 50000,
    "n_total_anchor_samples": 81805,
    "mean_f1": 0.9402932703361521,
    "std_f1": 0.0011329022179985494,
    "n_splits": 3
  },
  "training": {
    "best_model": "random_forest",
    "model_results": {
      "logistic_regression": {
        "best_params": {
          "classifier__solver": "saga",
          "classifier__penalty": "l2",
          "classifier__C": 10.0
        },
        "cv_f1": 0.9999914422393948,
        "val_f1": 1.0,
        "val_roc_auc": 1.0
      },
      "random_forest": {
        "best_params": {
          "classifier__n_estimators": 100,
          "classifier__min_samples_split": 20,
          "classifier__min_samples_leaf": 4,
          "classifier__max_depth": 5
        },
        "cv_f1": 0.9999572120756843,
        "val_f1": 1.0,
        "val_roc_auc": 1.0
      }
    }
  },
  "calibration": {
    "n_folds": 5,
    "confusion_matrix": {
      "tn": 73030,
      "fp": 2,
      "fn": 4,
      "tp": 8769
    },
    "tpr": 0.9995440556252138,
    "fpr": 2.738525577828897e-05
  },
  "estimates": {
    "naive_proportion": 0.059717510809887464,
    "predicted_proportion": 0.633361055417712,
    "acc_corrected_proportion": 0.6336399271138166,
    "wikipedia_analysis": {
      "n_sentences": 272476,
      "soft_estimate": 0.5723174620578524,
      "hard_estimate": 0.48938622117177294,
      "hard_threshold": 0.8
    },
    "descriptions": {
      "acc_corrected_proportion": "Adjusted true proportion of simple sentences in the full dataset using ACC calibration.",
      "wikipedia_soft_estimate": "Proportion of Vikidia-like simple sentences among complex-labelled Wikipedia sentences (soft estimate: mean P(Simple) over Wikipedia sentences).",
      "wikipedia_hard_estimate": "Proportion of Vikidia-like simple sentences among complex-labelled Wikipedia sentences (hard estimate: fraction with P(Simple) >= 0.8)."
    }
  },
  "prediction_analysis": {
    "threshold_for_hard_simple": 0.5,
    "confusion_matrix_full": {
      "tn": 103195,
      "fp": 169281,
      "fn": 3050,
      "tp": 14255,
      "n_sentences": 289781
    },
    "metrics_full": {
      "accuracy": 0.40530607596771356,
      "f1_simple_label0": 0.1419530872680379
    },
    "confusion_matrix_by_source": {
      "viki": {
        "tn": 0,
        "fp": 0,
        "fn": 3050,
        "tp": 14255,
        "n_sentences": 17305
      },
      "wiki": {
        "tn": 103195,
        "fp": 169281,
        "fn": 0,
        "tp": 0,
        "n_sentences": 272476
      }
    },
    "by_source_prevalence": {
      "viki": {
        "n_sentences": 17305,
        "naive_simple_proportion_label0": 1.0,
        "predicted_simple_soft_mean_prob": 0.7744163664698344,
        "predicted_simple_hard_prop_p>=threshold": 0.8237503611672927
      },
      "wiki": {
        "n_sentences": 272476,
        "naive_simple_proportion_label0": 0.0,
        "predicted_simple_soft_mean_prob": 0.5723174620578524,
        "predicted_simple_hard_prop_p>=threshold": 0.6212693962037024
      }
    },
    "length_bin_profile": [
      {
        "length_bin": "<=10",
        "n_sentences": 10327,
        "mean_p_simple": 0.9907588517542546,
        "hard_simple_prop": 0.9999031664568606
      },
      {
        "length_bin": "11-20",
        "n_sentences": 126442,
        "mean_p_simple": 0.9322537234798989,
        "hard_simple_prop": 0.995650179528954
      },
      {
        "length_bin": "21-30",
        "n_sentences": 91470,
        "mean_p_simple": 0.43983712273641384,
        "hard_simple_prop": 0.5173062206187821
      },
      {
        "length_bin": "31-40",
        "n_sentences": 39362,
        "mean_p_simple": 0.02040469847813529,
        "hard_simple_prop": 0.0
      },
      {
        "length_bin": ">=41",
        "n_sentences": 22180,
        "mean_p_simple": 0.009079562169891073,
        "hard_simple_prop": 0.0
      }
    ],
    "mislabel_stats": {
      "high_conf_threshold": 0.9,
      "low_conf_threshold": 0.09999999999999998,
      "complex_label_high_simple_prob_count": 100587,
      "simple_label_low_simple_prob_count": 2530,
      "total_candidates": 103117,
      "output_file": "c:\\Users\\chang\\iDEMRA\\results\\mislabel_candidates_en.csv"
    }
  }
}